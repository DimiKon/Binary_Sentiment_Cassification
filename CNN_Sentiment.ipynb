{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN_Sentiment.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### CNN Sentiment Classifier"
      ],
      "metadata": {
        "id": "-6di3JjeR4Zi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## import libraries"
      ],
      "metadata": {
        "id": "mMezv8uVUTPU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F1vgF2nCL8hJ"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import random\n",
        "import sys\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import seaborn as sns\n",
        "\n",
        "\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "from torchtext.legacy import data, vocab\n",
        "from torchtext.data.utils import get_tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def set_seed(seed = 1234):\n",
        "    \"\"\"\n",
        "    Function to set the seed of the entire notebook for reproducibility of results\n",
        "    \"\"\"\n",
        "    np.random.seed(seed)\n",
        "    random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    # When running on the CuDNN backend, two further options must be set\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    # Set a fixed value for the hash seed\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    \n",
        "set_seed()"
      ],
      "metadata": {
        "id": "U_kwfvAprP89"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## check for GPU"
      ],
      "metadata": {
        "id": "cas32K1rUYcc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Device available for running: \")\n",
        "print(device)"
      ],
      "metadata": {
        "id": "GcooRRR4ra0k",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "88a9c785-32d8-481c-e404-4b332aeda9b5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device available for running: \n",
            "cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. DATA"
      ],
      "metadata": {
        "id": "PW8u5PxIUcD8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## process data with Torchtext and TabularDataset"
      ],
      "metadata": {
        "id": "xmBAP5HXUhPW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a tokenizer\n",
        "tokenizer = get_tokenizer('spacy', language='en_core_web_sm')\n",
        "\n",
        "# Initialize torchtext Field objects\n",
        "# Convolutional layers expect the batch dimension to be first (batch_first = True)\n",
        "TEXT = data.Field(tokenize=tokenizer, lower=True, batch_first = True)\n",
        "LABEL = data.LabelField(dtype=torch.float)\n",
        "\n",
        "# Map data to fields\n",
        "fields = [('review', TEXT), ('sentiment', LABEL)]"
      ],
      "metadata": {
        "id": "DQ0_sMDQreK7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Use TabularDataset to create training, validation, and testing torch datasets (from csv)\n",
        "# by applying field objects, which were initialized beforehand\n",
        "\n",
        "train_data, valid_data, test_data = data.TabularDataset.splits( \n",
        "    path=\"/content/\", \n",
        "    train=\"data_train.csv\", \n",
        "    validation=\"data_dev.csv\",\n",
        "    test = \"data_test.csv\",\n",
        "    format=\"csv\", \n",
        "    skip_header=True, \n",
        "    fields=fields)\n",
        "\n",
        "print(f'Number of training examples: {len(train_data)}')\n",
        "print(f'Number of valid examples: {len(valid_data)}')\n",
        "print(f'Number of test examples: {len(test_data)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PChwpJPkvVqe",
        "outputId": "e233ed2c-f865-48b3-b3ed-b34df9e585b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of training examples: 40999\n",
            "Number of valid examples: 4500\n",
            "Number of test examples: 4501\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(vars(train_data.examples[0]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CJp53UMKyoV5",
        "outputId": "3dc824ba-3761-4947-cc0a-92e38826c9aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'review': ['this', 'is', 'in', 'short', 'the', 'tv', 'comedy', 'series', 'with', 'the', 'best', 'cast', 'ever', 'and', 'the', 'most', 'likable', 'also', 'each', 'one', 'of', 'them', 'is', 'first', 'hand', 'comedy', 'actor', 'know', 'only', 'one', 'tv', 'series', 'which', 'was', 'better', 'e', 'moonlighting', 'that', 'one', 'had', 'willis', 'as', 'lead', 'yet', 'it', 'had', 'willis', 'only', 'while', 'the', 'king', 'of', 'queens', 'has', 'pocketful', 'of', 'actors', 'that', 'are', 'as', 'fine', 'as', 'one', 'can', 'enjoy', 'kevin', 'james', 'leah', 'remini', 'jerry', 'stiller', 'patton', 'oswalt', 'nicole', 'sullivan', 'victor', 'williams', 'gary', 'valentine', 'and', 'even', 'all', 'the', 'rest', 'of', 'them', 'spontaneously', 'and', 'continually', 'and', 'promptly', 'liked', 'it', 'advancing', 'age', 'did', 'not', 'spoil', 'the', 'fun', 'anyway', 'in', 'few', 'words', 'the', 'series', 'is', 'intelligent', 'and', 'original', 'miraculously', 'spared', 'of', 'the', 'current', 'tv', 'stupidity', 'and', 'garbage', 'it', 'is', 'politically', 'incorrect', 'and', 'does', 'not', 'court', 'the', 'minorities', 'in', 'the', 'usual', 'disgusting', 'way', 'the', 'comic', 'is', 'very', 'palatable', 'and', 'savory', 'read', 'mostly', 'approvingly', 'few', 'imdb', 'writers', 'and', 'sometimes', 'they', 'write', 'about', 'their', 'favorite', 'shows', 'yet', 'though', 'these', 'writers', 'are', 'several', 'did', 'not', 'encountered', 'at', 'any', 'of', 'them', 'the', 'slightest', 'mention', 'of', 'my', 'favorite', 'tv', 'shows', 'but', 'it', 'is', 'true', 'that', 'the', 'critics', 'one', 'likes', 'are', 'not', 'those', 'with', 'whom', 'he', 'finds', 'himself', 'in', 'complete', 'approval', 'but', 'those', 'who', 'at', 'least', 'offer', 'common', 'basis', 'for', 'disapproval', 'which', 'are', 'mainly', 'wild', 'wild', 'west', 'moonlighting', 'queens', 'fantomas', 'the', '#', '#', 's', 'twilight', 'zone', 'bradbury', 'tv', 'show', 'and', 'sandokan', 'most', 'of', 'them', 'have', 'seen', 'when', 'was', '#', '#', '#', '#', 'yrs', 'about', 'few', 'of', 'them', 'have', 'written', 'and', 'execrably'], 'sentiment': '1'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## build Vocabulary (with or without Glove pretrained embeddings)"
      ],
      "metadata": {
        "id": "AAjC2Tf-aTzi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Build vocabulary objects (convert words into integers) for the training set\n",
        "\n",
        "MAX_VOCAB_SIZE = 20000\n",
        "\n",
        "# Without Glove (uncomment to run)\n",
        "#TEXT.build_vocab(train_data, max_size = MAX_VOCAB_SIZE)\n",
        "\n",
        "# With Glove pretrained (uncomment to run)\n",
        "# TEXT.build_vocab(train_data, max_size = MAX_VOCAB_SIZE, vectors = \"glove.6B.100d\",unk_init = torch.Tensor.normal_)\n",
        "                 \n",
        "\n",
        "LABEL.build_vocab(train_data)"
      ],
      "metadata": {
        "id": "JHdwUxubudCL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Unique tokens in TEXT vocabulary: {len(TEXT.vocab)}\")\n",
        "print(f\"Unique tokens in LABEL vocabulary: {len(LABEL.vocab)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pFUpijcjusrm",
        "outputId": "09a0bd89-c2f9-496c-88e5-e7a33dabe9e0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unique tokens in TEXT vocabulary: 20002\n",
            "Unique tokens in LABEL vocabulary: 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Most frequent tokens\n",
        "TEXT.vocab.freqs.most_common(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cquP8Xy5yfIj",
        "outputId": "08635741-0101-4cd4-e50b-3c98e844d23a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('the', 547738),\n",
              " ('and', 265893),\n",
              " ('of', 237095),\n",
              " ('to', 219592),\n",
              " ('is', 213467),\n",
              " ('it', 156349),\n",
              " ('in', 153092),\n",
              " ('this', 123727),\n",
              " ('that', 118573),\n",
              " ('#', 109039)]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## create iterators with BucketIterator"
      ],
      "metadata": {
        "id": "DYw9-tUiVUH3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 128\n",
        "\n",
        "train_iterator, valid_iterator, test_iterator = data.BucketIterator.splits(\n",
        "    (train_data, valid_data, test_data),\n",
        "    device = device,\n",
        "    batch_size = BATCH_SIZE, sort=False)\n",
        "  "
      ],
      "metadata": {
        "id": "lko1O-GA2kB7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. MODEL: CNN"
      ],
      "metadata": {
        "id": "jCMvizZPVmBr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CNN(nn.Module):\n",
        "\n",
        "  ''' Define network architecture and forward path. '''\n",
        "\n",
        "    def __init__(self, vocab_size, embedding_dim, n_filters, filter_sizes, output_dim, \n",
        "                 dropout, pad_idx):\n",
        "        \n",
        "        super().__init__()\n",
        "        \n",
        "        # Create word embeddings from the input words   \n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx = pad_idx)\n",
        "        \n",
        "         # Specify convolutions with filters of different sizes\n",
        "        self.convs = nn.ModuleList([\n",
        "                                    nn.Conv2d(in_channels = 1, \n",
        "                                              out_channels = n_filters, \n",
        "                                              kernel_size = (fs, embedding_dim)) \n",
        "                                    for fs in filter_sizes\n",
        "                                    ])\n",
        "        # Add a fully connected layer for final predicitons\n",
        "        self.fc = nn.Linear(len(filter_sizes) * n_filters, output_dim)\n",
        "        \n",
        "        # Drop some of the nodes for regularization\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "    def forward(self, text):\n",
        "\n",
        "      '''Forward path of the network.'''  \n",
        "                \n",
        "        #text = [batch size, sent len]\n",
        "        \n",
        "        embedded = self.embedding(text)\n",
        "                \n",
        "        #embedded = [batch size, sent len, emb dim]\n",
        "        \n",
        "        embedded = embedded.unsqueeze(1)\n",
        "        \n",
        "        #embedded = [batch size, 1, sent len, emb dim]\n",
        "        \n",
        "        conved = [F.relu(conv(embedded)).squeeze(3) for conv in self.convs]\n",
        "            \n",
        "        #conved_n = [batch size, n_filters, sent len - filter_sizes[n] + 1]\n",
        "                \n",
        "        pooled = [F.max_pool1d(conv, conv.shape[2]).squeeze(2) for conv in conved]\n",
        "        \n",
        "        #pooled_n = [batch size, n_filters]\n",
        "        \n",
        "        cat = self.dropout(torch.cat(pooled, dim = 1))\n",
        "\n",
        "        #cat = [batch size, n_filters * len(filter_sizes)]\n",
        "            \n",
        "        return self.fc(cat)"
      ],
      "metadata": {
        "id": "RkSoMeNLAU3c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. CREATE MODEL "
      ],
      "metadata": {
        "id": "QoyLsGVpWwkU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "INPUT_DIM = len(TEXT.vocab)\n",
        "EMBEDDING_DIM = 100\n",
        "N_FILTERS = 100\n",
        "FILTER_SIZES = [3,4,5]\n",
        "OUTPUT_DIM = 1\n",
        "DROPOUT = 0.2\n",
        "PAD_IDX = TEXT.vocab.stoi[TEXT.pad_token]\n",
        "\n",
        "model = CNN(INPUT_DIM, EMBEDDING_DIM, N_FILTERS, FILTER_SIZES, OUTPUT_DIM, DROPOUT, PAD_IDX)"
      ],
      "metadata": {
        "id": "24LCLYla95zp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## run this cell only if pretrained embeddings are used (else skip it and go on to the next one)"
      ],
      "metadata": {
        "id": "R37pUKqUeQiF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Copy the pre-trained word embeddings into the embedding layer\n",
        "pretrained_embeddings = TEXT.vocab.vectors\n",
        "\n",
        "# [vocab size, embedding dim]\n",
        "print(pretrained_embeddings.shape)\n",
        "\n",
        "# Copy the pre-trained word embeddings into the embedding layer\n",
        "model.embedding.weight.data.copy_(TEXT.vocab.vectors)\n",
        "print(model.embedding.weight)\n",
        "\n",
        "\n",
        "# Initialize <unk> and <pad> both to all zeros - irrelevant for sentiment analysis\n",
        "UNK_IDX = TEXT.vocab.stoi[TEXT.unk_token]\n",
        "\n",
        "# Setting row in the embedding weights matrix to zero using the token index\n",
        "model.embedding.weight.data[UNK_IDX] = torch.zeros(EMBEDDING_DIM)\n",
        "model.embedding.weight.data[PAD_IDX] = torch.zeros(EMBEDDING_DIM)\n",
        "\n",
        "# Freeze weights\n",
        "model.embedding.weight.requires_grad=False\n",
        "\n",
        "print(model.embedding.weight)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C3Nl8sN4ehQx",
        "outputId": "a7d2472a-06d7-4317-e6b7-658044a07f95"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([20002, 100])\n",
            "Parameter containing:\n",
            "tensor([[-0.1117, -0.4966,  0.1631,  ...,  1.2647, -0.2753, -0.1325],\n",
            "        [-0.8555, -0.7208,  1.3755,  ...,  0.0825, -1.1314,  0.3997],\n",
            "        [-0.0382, -0.2449,  0.7281,  ..., -0.1459,  0.8278,  0.2706],\n",
            "        ...,\n",
            "        [-0.2215, -0.0018,  0.7275,  ..., -0.6555, -0.4417,  0.4873],\n",
            "        [ 0.1070,  0.1660,  0.8914,  ..., -0.6368,  0.2450,  1.0492],\n",
            "        [-0.3429,  1.0147,  0.3113,  ..., -0.0477,  0.2576,  0.1918]],\n",
            "       requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "        [-0.0382, -0.2449,  0.7281,  ..., -0.1459,  0.8278,  0.2706],\n",
            "        ...,\n",
            "        [-0.2215, -0.0018,  0.7275,  ..., -0.6555, -0.4417,  0.4873],\n",
            "        [ 0.1070,  0.1660,  0.8914,  ..., -0.6368,  0.2450,  1.0492],\n",
            "        [-0.3429,  1.0147,  0.3113,  ..., -0.0477,  0.2576,  0.1918]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize <unk> and <pad> both to all zeros - irrelevant for sentiment analysis\n",
        "UNK_IDX = TEXT.vocab.stoi[TEXT.unk_token]\n",
        "\n",
        "# Setting row in the embedding weights matrix to zero using the token index\n",
        "model.embedding.weight.data[UNK_IDX] = torch.zeros(EMBEDDING_DIM)\n",
        "model.embedding.weight.data[PAD_IDX] = torch.zeros(EMBEDDING_DIM)\n",
        "\n",
        "print(model.embedding.weight.data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yQV5DEg7-PkE",
        "outputId": "8a70d7bb-1e5b-4c70-aa66-ad595e0365a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "        [ 0.7289, -0.7336,  1.5624,  ..., -0.5592, -0.4480, -0.6476],\n",
            "        ...,\n",
            "        [-0.4019, -1.6036,  0.7195,  ...,  0.8753,  1.2358,  0.2100],\n",
            "        [-0.2028,  0.4162, -0.0036,  ...,  0.7825,  0.1047,  1.1312],\n",
            "        [-0.0591,  0.4980, -0.3215,  ..., -0.6867,  0.5813,  1.2588]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Adam optimizer used to update the weights\n",
        "optimizer = optim.Adam(model.parameters(), lr=2e-2)\n",
        "\n",
        "# Loss function: binary cross entropy with logits\n",
        "# It restricts the predictions to a number between 0 and 1 using the logit function\n",
        "# then use the bound scarlar to calculate the loss using binary cross entropy\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "\n",
        "# Use GPU\n",
        "model = model.to(device)\n",
        "criterion = criterion.to(device)"
      ],
      "metadata": {
        "id": "ps56UZpL-sV4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Helper functions\n",
        "\n",
        "def batch_accuracy(predictions, label):\n",
        "    \"\"\"\n",
        "    Returns accuracy per batch.\n",
        "\n",
        "    predictions - float\n",
        "    label - 0 or 1\n",
        "    \"\"\"\n",
        "\n",
        "    # Round predictions to the closest integer using the sigmoid function\n",
        "    preds = torch.round(torch.sigmoid(predictions))\n",
        "    # If prediction is equal to label\n",
        "    correct = (preds == label).float()\n",
        "    # Average correct predictions\n",
        "    accuracy = correct.sum() / len(correct)\n",
        "\n",
        "    return accuracy\n",
        "\n",
        "def timer(start_time, end_time):\n",
        "    \"\"\"\n",
        "    Returns the minutes and seconds.\n",
        "    \"\"\"\n",
        "\n",
        "    time = end_time - start_time\n",
        "    mins = int(time / 60)\n",
        "    secs = int(time - (mins * 60))\n",
        "\n",
        "    return mins, secs"
      ],
      "metadata": {
        "id": "9zXhGSVm-wMw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, iterator, optimizer, criterion):\n",
        "    \"\"\"\n",
        "    Function to evaluate training loss and accuracy.\n",
        "\n",
        "    iterator - train iterator\n",
        "    \"\"\"\n",
        "    \n",
        "    # Cumulated Training loss\n",
        "    training_loss = 0.0\n",
        "    # Cumulated Training accuracy\n",
        "    training_acc = 0.0\n",
        "    \n",
        "    # Set model to training mode\n",
        "    model.train()\n",
        "    \n",
        "    # For each batch in the training iterator\n",
        "    for batch in iterator:\n",
        "        \n",
        "        # 1. Zero the gradients\n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        # 2. Compute the predictions\n",
        "        predictions = model(batch.review).squeeze(1)\n",
        "        \n",
        "        # 3. Compute loss\n",
        "        loss = criterion(predictions, batch.sentiment)\n",
        "        \n",
        "        # Compute accuracy\n",
        "        accuracy = batch_accuracy(predictions, batch.sentiment)\n",
        "        \n",
        "        # 4. Use loss to compute gradients\n",
        "        loss.backward()\n",
        "        \n",
        "        # 5. Use optimizer to take gradient step\n",
        "        optimizer.step()\n",
        "        \n",
        "        training_loss += loss.item()\n",
        "        training_acc += accuracy.item()\n",
        "    \n",
        "    # Return the loss and accuracy, averaged across each epoch\n",
        "    # len of iterator = num of batches in the iterator\n",
        "    return training_loss / len(iterator), training_acc / len(iterator)\n",
        "\n",
        "def evaluate(model, iterator, criterion):\n",
        "    \"\"\"\n",
        "    Function to evaluate the loss and accuracy of validation and test sets.\n",
        "\n",
        "    iterator - validation or test iterator\n",
        "    \"\"\"\n",
        "    \n",
        "    # Cumulated Training loss\n",
        "    eval_loss = 0.0\n",
        "    # Cumulated Training accuracy\n",
        "    eval_acc = 0\n",
        "    \n",
        "    # Set model to evaluation mode\n",
        "    model.eval()\n",
        "    \n",
        "    # Don't calculate the gradients\n",
        "    with torch.no_grad():\n",
        "    \n",
        "        for batch in iterator:\n",
        "            \n",
        "            predictions = model(batch.review).squeeze(1)\n",
        "            \n",
        "            loss = criterion(predictions, batch.sentiment)\n",
        "            \n",
        "            accuracy = batch_accuracy(predictions, batch.sentiment)\n",
        "\n",
        "            eval_loss += loss.item()\n",
        "            eval_acc += accuracy.item()\n",
        "        \n",
        "    return eval_loss / len(iterator), eval_acc / len(iterator)"
      ],
      "metadata": {
        "id": "GYGorybgjVcV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. TRAINING"
      ],
      "metadata": {
        "id": "U_NBZjWzXYE5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Number of epochs\n",
        "NUM_EPOCHS = 5\n",
        "\n",
        "# Lowest validation lost\n",
        "best_valid_loss = float('inf')\n",
        "\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "\n",
        "    start_time = time.time()\n",
        "    \n",
        "    # Evaluate training loss and accuracy\n",
        "    train_loss, train_acc = train(model, train_iterator, optimizer, criterion)\n",
        "    # Evaluate validation loss and accuracy\n",
        "    valid_loss, valid_acc = evaluate(model, valid_iterator, criterion)\n",
        "    \n",
        "    end_time = time.time()\n",
        "\n",
        "    mins, secs = timer(start_time, end_time)\n",
        "    \n",
        "    # At each epoch, if the validation loss is the best\n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        # Save the parameters of the model\n",
        "        torch.save(model.state_dict(), 'model.pt')\n",
        "\n",
        "    print(\"Epoch {}:\".format(epoch+1))\n",
        "    print(\"\\t Total Time: {}m {}s\".format(mins, secs))\n",
        "    print(\"\\t Train Loss {} | Train Accuracy: {}%\".format(round(train_loss, 2), round(train_acc*100, 2)))\n",
        "    print(\"\\t Validation Loss {} | Validation Accuracy: {}%\".format(round(valid_loss, 2), round(valid_acc*100, 2)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6rpzgcjij2H9",
        "outputId": "aa0bb281-693d-492d-969d-8c06750611fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1:\n",
            "\t Total Time: 0m 59s\n",
            "\t Train Loss 0.57 | Train Accuracy: 78.34%\n",
            "\t Validation Loss 0.34 | Validation Accuracy: 86.14%\n",
            "Epoch 2:\n",
            "\t Total Time: 0m 59s\n",
            "\t Train Loss 0.33 | Train Accuracy: 88.73%\n",
            "\t Validation Loss 0.3 | Validation Accuracy: 88.68%\n",
            "Epoch 3:\n",
            "\t Total Time: 0m 59s\n",
            "\t Train Loss 0.21 | Train Accuracy: 93.35%\n",
            "\t Validation Loss 0.52 | Validation Accuracy: 86.93%\n",
            "Epoch 4:\n",
            "\t Total Time: 1m 0s\n",
            "\t Train Loss 0.28 | Train Accuracy: 93.33%\n",
            "\t Validation Loss 0.99 | Validation Accuracy: 83.75%\n",
            "Epoch 5:\n",
            "\t Total Time: 0m 59s\n",
            "\t Train Loss 0.32 | Train Accuracy: 93.56%\n",
            "\t Validation Loss 1.19 | Validation Accuracy: 84.97%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. EVALUATING"
      ],
      "metadata": {
        "id": "gyGbFAlpXg0K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the model with the best validation loss\n",
        "model.load_state_dict(torch.load('model.pt'))\n",
        "\n",
        "# Evaluate test loss and accuracy\n",
        "test_loss, test_acc = evaluate(model, test_iterator, criterion)\n",
        "\n",
        "print(\"Test Loss: {} | Test Acc: {}%\".format(round(test_loss, 2), round(test_acc*100, 2)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "082DiSmNC6yz",
        "outputId": "663bb5b4-c5b8-4a30-f7ca-026ab9e9dcef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss: 0.33 | Test Acc: 87.12%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(model, text, min_len = 5):\n",
        "    \"\"\"\n",
        "    Function to predict the sentiment given a tweet\n",
        "    \"\"\"\n",
        "\n",
        "    # set model to evaluation mode\n",
        "    model.eval()\n",
        "\n",
        "    # the input sentence has to be at least as long as the largest filter height used\n",
        "    if len(text) < min_len:\n",
        "      text += ['<pad>'] * (min_len - len(text))\n",
        "    # index tokens by converting to the integer representation from the vocabulary\n",
        "    indexed_tokens = [TEXT.vocab.stoi[t] for t in text]\n",
        "    # convert the indices to a tensor\n",
        "    tensor = torch.LongTensor(indexed_tokens).to(device)\n",
        "    # add a batch dimension by unsqueezeing\n",
        "    tensor = tensor.unsqueeze(0)\n",
        "    # get prediction\n",
        "    prediction = torch.sigmoid(model(tensor))\n",
        "    # binarize prediction\n",
        "    y_pred_tag = torch.round(prediction)\n",
        "\n",
        "    return y_pred_tag"
      ],
      "metadata": {
        "id": "x8Z15POsDEfs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Use testing dataset for inference\n",
        "\n",
        "predicted_labels = []\n",
        "true_labels = []\n",
        "\n",
        "for i in range(4501):\n",
        "  with torch.no_grad():\n",
        "    text = test_data[i].review\n",
        "    label = test_data[i].sentiment\n",
        "    preds = predict(model, text)\n",
        "    predicted_labels.append(preds.cpu().numpy())\n",
        "    true_labels +=[int(label)]\n",
        "\n",
        "predicted_labels = [a.squeeze().tolist() for a in predicted_labels]\n",
        "predicted_labels = [int(a)for a in predicted_labels]\n",
        "\n",
        "#print(predicted_labels)\n",
        "#print(true_labels)"
      ],
      "metadata": {
        "id": "1RAktMmtDoza"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Confusion Matrix"
      ],
      "metadata": {
        "id": "KUGFLuNwX8PC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# metrics report\n",
        "target_names = ['class 0_negative', 'class 1_positive']\n",
        "scores = metrics.classification_report(true_labels, predicted_labels, target_names=target_names)\n",
        "print('best\\n')\n",
        "print(scores)\n",
        "mat = confusion_matrix(true_labels, predicted_labels)\n",
        "sns.heatmap(mat.T, square=True, annot=True, fmt='d', cbar=False)\n",
        "plt.xlabel('true label')\n",
        "plt.ylabel('predicted label')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "id": "YN5K5GtrKJtp",
        "outputId": "c7dde76a-e710-49ce-c550-e4b1782e17e9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "best\n",
            "\n",
            "                  precision    recall  f1-score   support\n",
            "\n",
            "class 0_negative       0.87      0.87      0.87      2250\n",
            "class 1_positive       0.87      0.87      0.87      2251\n",
            "\n",
            "        accuracy                           0.87      4501\n",
            "       macro avg       0.87      0.87      0.87      4501\n",
            "    weighted avg       0.87      0.87      0.87      4501\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(91.68, 0.5, 'predicted label')"
            ]
          },
          "metadata": {},
          "execution_count": 22
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}